{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d392b565-36b0-43ab-842f-9dfed7cb1e73",
   "metadata": {},
   "source": [
    "# GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf06caa-e159-408d-a275-53102bad54e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews scraped: 487\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL of the website with reviews\n",
    "base_url = 'https://www.trustpilot.com/review/www.gap.com'\n",
    "\n",
    "# Initialize an empty list to store the extracted data\n",
    "reviews_data = []\n",
    "\n",
    "# Function to scrape reviews from a specific page\n",
    "def scrape_reviews(page_number):\n",
    "    if page_number == 1:\n",
    "        url = base_url  # First page doesn't have the `?page=` parameter\n",
    "    else:\n",
    "        url = f\"{base_url}?page={page_number}\"  # Other pages have `?page=`\n",
    "        \n",
    "    # Send a GET request to fetch the HTML content\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page {page_number}: {response.status_code}\")\n",
    "        return\n",
    "    \n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "    # Find all review sections\n",
    "    reviews = soup.find_all('section', class_='styles_reviewContentwrapper__zH_9M')\n",
    "\n",
    "    # Loop through each review section and extract the details\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            # Extract the rating\n",
    "            rating = review.find('div', class_='styles_reviewHeader__iU9Px')['data-service-review-rating']\n",
    "        except (TypeError, AttributeError):\n",
    "            rating = None  # Set rating to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the review title\n",
    "            review_title = review.find('h2', {'data-service-review-title-typography': 'true'}).text.strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            review_title = None  # Set title to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the review content\n",
    "            review_content = review.find('p', {'data-service-review-text-typography': 'true'}).text.strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            review_content = None  # Set content to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the date of experience\n",
    "            date_of_experience = review.find('p', {'data-service-review-date-of-experience-typography': 'true'}).text.split(':')[-1].strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            date_of_experience = None  # Set date to None if extraction fails\n",
    "\n",
    "        # Append the extracted data to the reviews_data list\n",
    "        reviews_data.append({\n",
    "            'Rating': rating,\n",
    "            'Review Title': review_title,\n",
    "            'Review Content': review_content,\n",
    "            'Date of Experience': date_of_experience\n",
    "        })\n",
    "\n",
    "# Scrape reviews from all pages (1 to 25)\n",
    "for page in range(1, 26):\n",
    "    scrape_reviews(page)\n",
    "\n",
    "# Convert the reviews data into a pandas DataFrame\n",
    "df_gap = pd.DataFrame(reviews_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(f\"Total reviews scraped: {len(df_gap)}\")\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "#df.to_csv('scraped_reviews.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61518b4b-ed71-4db3-aa11-b723b7397a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Content</th>\n",
       "      <th>Date of Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WARNING WARNING WARNING</td>\n",
       "      <td>WARNING WARNING WARNING — DO NOT ORDER FROM GA...</td>\n",
       "      <td>September 22, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Carrier will leave your package anywhere</td>\n",
       "      <td>Order from them they used some other carrier n...</td>\n",
       "      <td>September 24, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely terrible online service in…</td>\n",
       "      <td>Absolutely terrible online service in addition...</td>\n",
       "      <td>August 13, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>GAP Bridgewater, NJ  team is AWESOME</td>\n",
       "      <td>GAP Bridgewater, NJ  team is AWESOME. They hel...</td>\n",
       "      <td>August 10, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>terrible customer service</td>\n",
       "      <td>the customer service people at Gap couldn't sp...</td>\n",
       "      <td>May 29, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating                              Review Title  \\\n",
       "0      1                   WARNING WARNING WARNING   \n",
       "1      1  Carrier will leave your package anywhere   \n",
       "2      1    Absolutely terrible online service in…   \n",
       "3      5      GAP Bridgewater, NJ  team is AWESOME   \n",
       "4      1                 terrible customer service   \n",
       "\n",
       "                                      Review Content  Date of Experience  \n",
       "0  WARNING WARNING WARNING — DO NOT ORDER FROM GA...  September 22, 2024  \n",
       "1  Order from them they used some other carrier n...  September 24, 2024  \n",
       "2  Absolutely terrible online service in addition...     August 13, 2024  \n",
       "3  GAP Bridgewater, NJ  team is AWESOME. They hel...     August 10, 2024  \n",
       "4  the customer service people at Gap couldn't sp...        May 29, 2024  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b6622-df11-4ce1-a980-a7623ca7250f",
   "metadata": {},
   "source": [
    "# Old NAvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51220bff-4b54-47e4-9203-dc1540a44588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews scraped: 421\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL of the website with reviews\n",
    "base_url = 'https://www.trustpilot.com/review/oldnavy.ca'\n",
    "\n",
    "# Initialize an empty list to store the extracted data\n",
    "reviews_data = []\n",
    "\n",
    "# Function to scrape reviews from a specific page\n",
    "def scrape_reviews(page_number):\n",
    "    if page_number == 1:\n",
    "        url = base_url  # First page doesn't have the `?page=` parameter\n",
    "    else:\n",
    "        url = f\"{base_url}?page={page_number}\"  # Other pages have `?page=`\n",
    "\n",
    "    #print(f\"Scraping page {page_number}...\")\n",
    "    \n",
    "    # Send a GET request to fetch the HTML content\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page {page_number}: {response.status_code}\")\n",
    "        return\n",
    "    \n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "    # Find all review sections\n",
    "    reviews = soup.find_all('section', class_='styles_reviewContentwrapper__zH_9M')\n",
    "\n",
    "    # Loop through each review section and extract the details\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            # Extract the rating\n",
    "            rating = review.find('div', class_='styles_reviewHeader__iU9Px')['data-service-review-rating']\n",
    "        except (TypeError, AttributeError):\n",
    "            rating = None  # Set rating to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the review title\n",
    "            review_title = review.find('h2', {'data-service-review-title-typography': 'true'}).text.strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            review_title = None  # Set title to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the review content\n",
    "            review_content = review.find('p', {'data-service-review-text-typography': 'true'}).text.strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            review_content = None  # Set content to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the date of experience\n",
    "            date_of_experience = review.find('p', {'data-service-review-date-of-experience-typography': 'true'}).text.split(':')[-1].strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            date_of_experience = None  # Set date to None if extraction fails\n",
    "\n",
    "        # Append the extracted data to the reviews_data list\n",
    "        reviews_data.append({\n",
    "            'Rating': rating,\n",
    "            'Review Title': review_title,\n",
    "            'Review Content': review_content,\n",
    "            'Date of Experience': date_of_experience\n",
    "        })\n",
    "\n",
    "# Scrape reviews from all pages (1 to 25)\n",
    "for page in range(1, 23):\n",
    "    scrape_reviews(page)\n",
    "\n",
    "# Convert the reviews data into a pandas DataFrame\n",
    "df_old_navy = pd.DataFrame(reviews_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(f\"Total reviews scraped: {len(df_old_navy)}\")\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "#df.to_csv('scraped_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28aca1ce-fcad-4b6b-99d3-b93f8e69c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Content</th>\n",
       "      <th>Date of Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Affordable clothes</td>\n",
       "      <td>Great clothes and customer service. I DONT kno...</td>\n",
       "      <td>August 20, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Old Navy uses OnTrac/Lasership for…</td>\n",
       "      <td>Old Navy uses OnTrac/Lasership for deliver. Th...</td>\n",
       "      <td>August 02, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>If 1 could give 0 stars I would</td>\n",
       "      <td>If 1 could give 0 stars I would. per old navy ...</td>\n",
       "      <td>August 19, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>STOP USING LASERSHIP/ONTRAC</td>\n",
       "      <td>Old Navy’s products are fine for the price. Th...</td>\n",
       "      <td>August 02, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ordered a bathing suit for my…</td>\n",
       "      <td>Ordered a bathing suit for my granddaughter.  ...</td>\n",
       "      <td>July 20, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating                         Review Title  \\\n",
       "0      5                   Affordable clothes   \n",
       "1      1  Old Navy uses OnTrac/Lasership for…   \n",
       "2      1      If 1 could give 0 stars I would   \n",
       "3      1          STOP USING LASERSHIP/ONTRAC   \n",
       "4      1       Ordered a bathing suit for my…   \n",
       "\n",
       "                                      Review Content Date of Experience  \n",
       "0  Great clothes and customer service. I DONT kno...    August 20, 2024  \n",
       "1  Old Navy uses OnTrac/Lasership for deliver. Th...    August 02, 2024  \n",
       "2  If 1 could give 0 stars I would. per old navy ...    August 19, 2024  \n",
       "3  Old Navy’s products are fine for the price. Th...    August 02, 2024  \n",
       "4  Ordered a bathing suit for my granddaughter.  ...      July 20, 2024  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc765fb-7b40-4917-80ad-5b6386a94e34",
   "metadata": {},
   "source": [
    "# Banana Republic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62d364c1-fed1-49ec-a0ca-ad97be45e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews scraped: 124\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL of the website with reviews\n",
    "base_url = 'https://www.trustpilot.com/review/bananarepublic.eu'\n",
    "\n",
    "# Initialize an empty list to store the extracted data\n",
    "reviews_data = []\n",
    "\n",
    "# Function to scrape reviews from a specific page\n",
    "def scrape_reviews(page_number):\n",
    "    if page_number == 1:\n",
    "        url = base_url  # First page doesn't have the `?page=` parameter\n",
    "    else:\n",
    "        url = f\"{base_url}?page={page_number}\"  # Other pages have `?page=`\n",
    "\n",
    "    #print(f\"Scraping page {page_number}...\")\n",
    "    \n",
    "    # Send a GET request to fetch the HTML content\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page {page_number}: {response.status_code}\")\n",
    "        return\n",
    "    \n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "    # Find all review sections\n",
    "    reviews = soup.find_all('section', class_='styles_reviewContentwrapper__zH_9M')\n",
    "\n",
    "    # Loop through each review section and extract the details\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            # Extract the rating\n",
    "            rating = review.find('div', class_='styles_reviewHeader__iU9Px')['data-service-review-rating']\n",
    "        except (TypeError, AttributeError):\n",
    "            rating = None  # Set rating to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the review title\n",
    "            review_title = review.find('h2', {'data-service-review-title-typography': 'true'}).text.strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            review_title = None  # Set title to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the review content\n",
    "            review_content = review.find('p', {'data-service-review-text-typography': 'true'}).text.strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            review_content = None  # Set content to None if extraction fails\n",
    "\n",
    "        try:\n",
    "            # Extract the date of experience\n",
    "            date_of_experience = review.find('p', {'data-service-review-date-of-experience-typography': 'true'}).text.split(':')[-1].strip()\n",
    "        except (AttributeError, TypeError):\n",
    "            date_of_experience = None  # Set date to None if extraction fails\n",
    "\n",
    "        # Append the extracted data to the reviews_data list\n",
    "        reviews_data.append({\n",
    "            'Rating': rating,\n",
    "            'Review Title': review_title,\n",
    "            'Review Content': review_content,\n",
    "            'Date of Experience': date_of_experience\n",
    "        })\n",
    "\n",
    "# Scrape reviews from all pages (1 to 25)\n",
    "for page in range(1, 8):\n",
    "    scrape_reviews(page)\n",
    "\n",
    "# Convert the reviews data into a pandas DataFrame\n",
    "df_banana_republic = pd.DataFrame(reviews_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(f\"Total reviews scraped: {len(df_banana_republic)}\")\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "#df.to_csv('scraped_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "156647b3-51c7-49ba-846b-1ddc47579218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Content</th>\n",
       "      <th>Date of Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am trying to return items I ordered…</td>\n",
       "      <td>I am trying to return items I ordered from Ban...</td>\n",
       "      <td>September 23, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Please don't order from this company</td>\n",
       "      <td>Please don't order from this company. I wish I...</td>\n",
       "      <td>September 16, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Shapeless, happless mass</td>\n",
       "      <td>I used to love Banana Republic, bought many of...</td>\n",
       "      <td>August 23, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sends garbage as final sale</td>\n",
       "      <td>I purchased two final sale items from Banana R...</td>\n",
       "      <td>August 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I used to work in the Banana Republic…</td>\n",
       "      <td>I used to work in the Banana Republic in Marke...</td>\n",
       "      <td>August 30, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating                            Review Title  \\\n",
       "0      1  I am trying to return items I ordered…   \n",
       "1      1    Please don't order from this company   \n",
       "2      1                Shapeless, happless mass   \n",
       "3      1             Sends garbage as final sale   \n",
       "4      4  I used to work in the Banana Republic…   \n",
       "\n",
       "                                      Review Content  Date of Experience  \n",
       "0  I am trying to return items I ordered from Ban...  September 23, 2024  \n",
       "1  Please don't order from this company. I wish I...  September 16, 2024  \n",
       "2  I used to love Banana Republic, bought many of...     August 23, 2024  \n",
       "3  I purchased two final sale items from Banana R...     August 26, 2024  \n",
       "4  I used to work in the Banana Republic in Marke...     August 30, 2024  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_banana_republic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158c7903-93e6-4a5e-a72a-4cfc52c04b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb78fe46-eb56-4694-b70d-83fee184afa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rating                                 Review Title  \\\n",
      "0        1                      WARNING WARNING WARNING   \n",
      "1        1     Carrier will leave your package anywhere   \n",
      "2        1       Absolutely terrible online service in…   \n",
      "3        5         GAP Bridgewater, NJ  team is AWESOME   \n",
      "4        1                    terrible customer service   \n",
      "..     ...                                          ...   \n",
      "482      4                                   good stuff   \n",
      "483      5                          Nothing but ok.....   \n",
      "484      5                        Best prices for Jeans   \n",
      "485      1  They say they \"can't\" and they mean \"won't\"   \n",
      "486      1                               don't go there   \n",
      "\n",
      "                                        Review Content  Date of Experience  \\\n",
      "0    WARNING WARNING WARNING — DO NOT ORDER FROM GA...  September 22, 2024   \n",
      "1    Order from them they used some other carrier n...  September 24, 2024   \n",
      "2    Absolutely terrible online service in addition...     August 13, 2024   \n",
      "3    GAP Bridgewater, NJ  team is AWESOME. They hel...     August 10, 2024   \n",
      "4    the customer service people at Gap couldn't sp...        May 29, 2024   \n",
      "..                                                 ...                 ...   \n",
      "482                 good stuff...better at sale prices   November 04, 2011   \n",
      "483  I order.......and got all deliverd 3 dayes lat...   November 03, 2011   \n",
      "484  I love the huge selection then have on their w...   December 18, 2010   \n",
      "485  I tried to return a birthday present I'd bough...   November 30, 2009   \n",
      "486  I purchased some jeans for my daughters for Ch...    October 24, 2009   \n",
      "\n",
      "    Sentiment  \n",
      "0    negative  \n",
      "1    negative  \n",
      "2    negative  \n",
      "3    positive  \n",
      "4    negative  \n",
      "..        ...  \n",
      "482  positive  \n",
      "483   neutral  \n",
      "484  positive  \n",
      "485  negative  \n",
      "486   neutral  \n",
      "\n",
      "[487 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure API credentials\n",
    "endpoint = \"https://dhairya1899.cognitiveservices.azure.com/\"\n",
    "key = \"79f35fa73b5c4ff08a284193f18068cf\"\n",
    "\n",
    "# Authenticate client\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Function for sentiment analysis\n",
    "def sentiment_analysis_example(client, review):\n",
    "    documents = [review]\n",
    "    response = client.analyze_sentiment(documents=documents)[0]\n",
    "    sentiments = []\n",
    "    for sentence in response.sentences:\n",
    "        sentiments.append(sentence.sentiment)\n",
    "    return sentiments[0]  # Get the overall sentiment of the first sentence\n",
    "\n",
    "# Initialize rate limiting variables\n",
    "requests_per_second_limit = 100\n",
    "requests_per_minute_limit = 300\n",
    "time_start = time.time()\n",
    "\n",
    "# Function to handle rate limiting\n",
    "def handle_rate_limit(request_count, start_time, per_second_limit, per_minute_limit):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if request_count % per_second_limit == 0:\n",
    "        if elapsed_time < 1:\n",
    "            time.sleep(1 - elapsed_time)\n",
    "    if request_count % per_minute_limit == 0:\n",
    "        if elapsed_time < 60:\n",
    "            time.sleep(60 - elapsed_time)\n",
    "    return time.time()\n",
    "\n",
    "# Perform sentiment analysis with rate limiting\n",
    "azure_sentiments = []\n",
    "for i, review in enumerate(df_gap['Review Content']):\n",
    "    if pd.notna(review):\n",
    "        sentiment = sentiment_analysis_example(client, review)\n",
    "        azure_sentiments.append(sentiment)\n",
    "        \n",
    "        # Handle API rate limit\n",
    "        time_start = handle_rate_limit(i + 1, time_start, requests_per_second_limit, requests_per_minute_limit)\n",
    "    else:\n",
    "        azure_sentiments.append(None)\n",
    "\n",
    "# Add the sentiment results back to the DataFrame\n",
    "df_gap['Sentiment'] = azure_sentiments\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6648e395-f683-4bf1-a9db-0cf5046380eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "negative    287\n",
      "neutral     104\n",
      "positive     85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_summary_gap = df_gap['Sentiment'].value_counts()\n",
    "print(sentiment_summary_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de447e1-9626-4e60-92b9-39083f0890df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating                         Review Title  \\\n",
      "0      5                   Affordable clothes   \n",
      "1      1  Old Navy uses OnTrac/Lasership for…   \n",
      "2      1      If 1 could give 0 stars I would   \n",
      "3      1          STOP USING LASERSHIP/ONTRAC   \n",
      "4      1       Ordered a bathing suit for my…   \n",
      "\n",
      "                                      Review Content Date of Experience  \\\n",
      "0  Great clothes and customer service. I DONT kno...    August 20, 2024   \n",
      "1  Old Navy uses OnTrac/Lasership for deliver. Th...    August 02, 2024   \n",
      "2  If 1 could give 0 stars I would. per old navy ...    August 19, 2024   \n",
      "3  Old Navy’s products are fine for the price. Th...    August 02, 2024   \n",
      "4  Ordered a bathing suit for my granddaughter.  ...      July 20, 2024   \n",
      "\n",
      "  Sentiment  \n",
      "0  positive  \n",
      "1   neutral  \n",
      "2  negative  \n",
      "3  positive  \n",
      "4  positive  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure API credentials\n",
    "endpoint = \"https://dhairya1899.cognitiveservices.azure.com/\"\n",
    "key = \"79f35fa73b5c4ff08a284193f18068cf\"\n",
    "\n",
    "# Authenticate client\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Function for sentiment analysis\n",
    "def sentiment_analysis_example(client, review):\n",
    "    documents = [review]\n",
    "    response = client.analyze_sentiment(documents=documents)[0]\n",
    "    sentiments = []\n",
    "    for sentence in response.sentences:\n",
    "        sentiments.append(sentence.sentiment)\n",
    "    return sentiments[0]  # Get the overall sentiment of the first sentence\n",
    "\n",
    "# Initialize rate limiting variables\n",
    "requests_per_second_limit = 100\n",
    "requests_per_minute_limit = 300\n",
    "time_start = time.time()\n",
    "\n",
    "# Function to handle rate limiting\n",
    "def handle_rate_limit(request_count, start_time, per_second_limit, per_minute_limit):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if request_count % per_second_limit == 0:\n",
    "        if elapsed_time < 1:\n",
    "            time.sleep(1 - elapsed_time)\n",
    "    if request_count % per_minute_limit == 0:\n",
    "        if elapsed_time < 60:\n",
    "            time.sleep(60 - elapsed_time)\n",
    "    return time.time()\n",
    "\n",
    "# Perform sentiment analysis with rate limiting\n",
    "azure_sentiments = []\n",
    "for i, review in enumerate(df_old_navy['Review Content']):\n",
    "    if pd.notna(review):\n",
    "        sentiment = sentiment_analysis_example(client, review)\n",
    "        azure_sentiments.append(sentiment)\n",
    "        \n",
    "        # Handle API rate limit\n",
    "        time_start = handle_rate_limit(i + 1, time_start, requests_per_second_limit, requests_per_minute_limit)\n",
    "    else:\n",
    "        azure_sentiments.append(None)\n",
    "\n",
    "# Add the sentiment results back to the DataFrame\n",
    "df_old_navy['Sentiment'] = azure_sentiments\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_old_navy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a7664eb-a494-412e-85fa-0d7c8b49f1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "negative    252\n",
      "neutral     115\n",
      "positive     49\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_summary_old_navy = df_old_navy['Sentiment'].value_counts()\n",
    "print(sentiment_summary_old_navy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d25db37-678d-41a8-b04b-e6aa33702e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating                            Review Title  \\\n",
      "0      1  I am trying to return items I ordered…   \n",
      "1      1    Please don't order from this company   \n",
      "2      1                Shapeless, happless mass   \n",
      "3      1             Sends garbage as final sale   \n",
      "4      4  I used to work in the Banana Republic…   \n",
      "\n",
      "                                      Review Content  Date of Experience  \\\n",
      "0  I am trying to return items I ordered from Ban...  September 23, 2024   \n",
      "1  Please don't order from this company. I wish I...  September 16, 2024   \n",
      "2  I used to love Banana Republic, bought many of...     August 23, 2024   \n",
      "3  I purchased two final sale items from Banana R...     August 26, 2024   \n",
      "4  I used to work in the Banana Republic in Marke...     August 30, 2024   \n",
      "\n",
      "  Sentiment  \n",
      "0   neutral  \n",
      "1  negative  \n",
      "2  positive  \n",
      "3   neutral  \n",
      "4   neutral  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure API credentials\n",
    "endpoint = \"https://dhairya1899.cognitiveservices.azure.com/\"\n",
    "key = \"79f35fa73b5c4ff08a284193f18068cf\"\n",
    "\n",
    "# Authenticate client\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Function for sentiment analysis\n",
    "def sentiment_analysis_example(client, review):\n",
    "    documents = [review]\n",
    "    response = client.analyze_sentiment(documents=documents)[0]\n",
    "    sentiments = []\n",
    "    for sentence in response.sentences:\n",
    "        sentiments.append(sentence.sentiment)\n",
    "    return sentiments[0]  # Get the overall sentiment of the first sentence\n",
    "\n",
    "# Initialize rate limiting variables\n",
    "requests_per_second_limit = 100\n",
    "requests_per_minute_limit = 300\n",
    "time_start = time.time()\n",
    "\n",
    "# Function to handle rate limiting\n",
    "def handle_rate_limit(request_count, start_time, per_second_limit, per_minute_limit):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if request_count % per_second_limit == 0:\n",
    "        if elapsed_time < 1:\n",
    "            time.sleep(1 - elapsed_time)\n",
    "    if request_count % per_minute_limit == 0:\n",
    "        if elapsed_time < 60:\n",
    "            time.sleep(60 - elapsed_time)\n",
    "    return time.time()\n",
    "\n",
    "# Perform sentiment analysis with rate limiting\n",
    "azure_sentiments = []\n",
    "for i, review in enumerate(df_banana_republic['Review Content']):\n",
    "    if pd.notna(review):\n",
    "        sentiment = sentiment_analysis_example(client, review)\n",
    "        azure_sentiments.append(sentiment)\n",
    "        \n",
    "        # Handle API rate limit\n",
    "        time_start = handle_rate_limit(i + 1, time_start, requests_per_second_limit, requests_per_minute_limit)\n",
    "    else:\n",
    "        azure_sentiments.append(None)\n",
    "\n",
    "# Add the sentiment results back to the DataFrame\n",
    "df_banana_republic['Sentiment'] = azure_sentiments\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_banana_republic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ab9bad8-7a13-4f25-88e5-c1de43b009b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "negative    69\n",
      "neutral     30\n",
      "positive    24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_banana_republic = df_banana_republic['Sentiment'].value_counts()\n",
    "print(sentiment_banana_republic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4876579f-8a63-4a1f-a015-9a174d54853c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score Old Navy\n",
      "Sentiment\n",
      "negative    60.576923\n",
      "neutral     27.644231\n",
      "positive    11.778846\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each sentiment\n",
    "print(f'Sentiment Score Old Navy')\n",
    "sentiment_counts = df_old_navy['Sentiment'].value_counts()\n",
    "# Calculate total counts\n",
    "total_counts = sentiment_counts.sum()\n",
    "# Calculate percentages\n",
    "sentiment_percentages = (sentiment_counts / total_counts) * 100\n",
    "# Print the percentages\n",
    "print(sentiment_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7a5fd-ab94-4c68-a74f-eb81cd432db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
